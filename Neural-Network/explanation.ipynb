{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Delta Rule",
   "id": "53ab8a89923108a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The delta rule, also known as the Widrow-Hoff learning rule, is a fundamental algorithm used to train single-layer neural networks. It's a supervised learning technique that adjusts the weights and biases of the network based on the error between the predicted output and the actual target output.\n",
    "\n",
    "Delta rule:\n",
    "$$ \\theta_{new} = \\theta_{old} + \\Delta \\theta$$\n",
    "$$ W_{new} = W_{old} + \\Delta W$$\n",
    "Where:\n",
    "$$\\Delta \\theta = - \\eta (o-y)$$\n",
    "$$\\Delta W = \\eta (o-y)x_i$$\n",
    "- $x_i$: input\n",
    "- $\\eta$: learning rate\n",
    "- $o$: desired output\n",
    "- $y$: obtained output\n",
    "\n",
    "**Online Learning**\n",
    "\n",
    "In online learning, each training example is used to update the weights and biases immediately.\n",
    "\n",
    "Algorithm:\n",
    "1. Initialize weights and bias: Assign random values to the weights and bias.\n",
    "2. Present input: Feed an input pattern to the network.\n",
    "3. Calculate output: Compute the network's output using the current weights and bias.\n",
    "4. Calculate error: Determine the error between the desired output and the actual output.\n",
    "5. Update weights and bias: Adjust the weights and bias using the delta rule\n",
    "\n",
    "**Batch Learning**\n",
    "In batch learning, all training examples are used to calculate the weight and bias updates, and the updates are applied simultaneously after processing all examples.\n",
    "\n",
    "Algorithm:\n",
    "\n",
    "1. Initialize weights and bias: Assign random values to the weights and bias.\n",
    "2. Present all inputs: Feed all input patterns to the network.\n",
    "3. Calculate outputs and errors: Compute the output and error for each input pattern.\n",
    "4. Accumulate weight and bias updates: For each input pattern, calculate the weight and bias updates and accumulate them.\n",
    "5. Update weights and bias: After processing all input patterns, update the weights and bias using the accumulated updates:"
   ],
   "id": "23a8b9b44d3c08aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training on MNIST data",
   "id": "1ff9802eb45a7476"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Input Layer**\n",
    "\n",
    "- Each handwritten digit image is 28×28 pixels, which means 784 input neurons (28×28).\n",
    "- The pixel values range from 0 to 255, which are normalized by dividing by 256 to ensure the values lie between 0 and 1.\n",
    "\n",
    "**Output Layer**\n",
    "\n",
    "- This layer contains 10 neurons, one for each digit (0–9).\n",
    "- The output neuron with the highest value represents the predicted digit.\n",
    "\n",
    "**Hidden Layers**\n",
    "- The network contains two hidden layers, each with 16 neurons.\n",
    "- Each hidden layer processes the data and extracts features relevant for classification.\n",
    "- Bias neurons are added to the layers to allow more flexibility in learning the relationships between inputs and outputs."
   ],
   "id": "5f399a888f021d5f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## An overview on MLP",
   "id": "ad88ab717b616a2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For each neuron, the computation is as follows:\n",
    "$$z = \\sum w_i x_i + b$$\n",
    "$$ y = f_{act}(z)$$\n",
    "Where:\n",
    "- $x_i$ : Input value\n",
    "- $w_i$ : Weights for each input\n",
    "- $b$ : Bias term\n",
    "- $z$ : Weighted sum of the inputs\n",
    "- $y$ : Output after applying activation function\n",
    "Here the activation function is *sigmoid*, $f_{act}(z) = \\sigma(z) = \\frac{1}{1 + e ^ {-z}}$."
   ],
   "id": "1124eb28d7483c8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## A. Ordinary way",
   "id": "2f23363e8e19fb57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Weight Initialization**\n",
    "- Weights determine *the strength of connections between neurons*.\n",
    "- They are initialized with small random values (normal distribution).\n",
    "- Biases start at 0 and are adjusted during training."
   ],
   "id": "fc01ed12a7a9d968"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### A.Results",
   "id": "8b86975497fd2d5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5ce5921bbd9f96f0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
